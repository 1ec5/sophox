import time
from collections import defaultdict

from pywikiapi import Site, AttrDict
from pywikibot import Site as PbSite

from .CacheInstances import Caches
from .ItemFromWiki import ItemFromWiki
from .UploadItem import UploadItem
from .Properties import P_INSTANCE_OF, P_KEY_ID, P_TAG_ID, P_TAG_KEY
from .utils import get_entities, list_to_dict_of_lists, sitelink_normalizer, strid_from_item


class Processor:

    def __init__(self, opts, caches: Caches, site: Site, pb_site: PbSite) -> None:
        self.opts = AttrDict(opts)
        self.caches = caches
        self.site = site
        self.pb_site = pb_site

        wiki_items = (
                []
                + self.caches.keydescription.get()
                + self.caches.tagdescription.get()
        )

        # For each variant of str_id, count how many variants there are.
        # Ideally should be 1 for each, but if something defines two variants,
        # e.g. "Key:blah_blah" and "Key:blah blah",
        # each of the values will have 2 or more
        self.str_id_variants_count = defaultdict(int)
        for s in [
            set(lst)
            for k, lst in list_to_dict_of_lists(
                [v.str_id for v in self.caches.descriptionParsed.get() if v.str_id],
                lambda v: sitelink_normalizer(v)).items()
        ]:
            for v in s:
                self.str_id_variants_count[v] = len(s)
            if len(s) > 1:
                print('Ambiguous entries: "' + '", "'.join(s) + '"')

        existing_items_strids = set(self.caches.itemKeysByStrid.get().keys())

        self.new_items_strids = set([v.str_id for v in wiki_items
                                     # if 'direction' in v.str_id  #DEBUG
                                     ]) - existing_items_strids

        self.autogenerated_keys = set()
        self.all_items_by_strid = {
            **self.items_by_strid(P_KEY_ID, reload_on_error=False),
            **self.items_by_strid(P_TAG_ID, reload_on_error=False),
        }

        self.wiki_items_by_id = list_to_dict_of_lists(wiki_items, lambda v: v.str_id)

    def items_by_strid(self, prop, fix_multiple=False, reload_on_error=True):
        result = {}
        errors_fixed = False
        for item in self.caches.data_items.get():
            qid = item.id
            try:
                values = prop.get_claim_value(item, allow_multiple=True)
                if not values or len(values) == 0:
                    continue
                if len(values) == 1:
                    result[values[0]] = item
                    continue
                if reload_on_error:
                    # reload and re-parse item just in case we had stale data
                    print(f'Multiple keys found in { self.caches.qitem(qid)}, reloading')
                    item = get_entities(self.site, qid)
                    if item:
                        values = prop.get_claim_value(item, allow_multiple=True)
                        if not values or len(values) == 0:
                            continue
                        if len(values) == 1:
                            result[values[0]] = item
                            continue
                if not fix_multiple:
                    raise ValueError('Found multiple key ids ')
                if len(set(values)) > 1:
                    raise ValueError('Found multiple different keys')

                print(f'Removing multiple duplicate keys from { self.caches.qitem(qid)}...')
                raise ValueError('Not implemented')
                # if not self.allow_edit(prop, qid):
                #     continue
                # pbitem = pb.ItemPage(self.pb_site, qid)
                # pbitem.get()
                # pbitem.removeClaims(pbitem.claims[prop.id][1:], summary="Removed duplicate keys")
                # errors_fixed = True

            except ValueError as err:
                print(f'Error parsing key id from { self.caches.qitem(qid)}: {err}')

        if errors_fixed:
            time.sleep(5)
            self.caches.items.regenerate()
            return self.items_by_strid(prop, fix_multiple=False, reload_on_error=False)
        else:
            return result

    def run(self, mode):
        if mode == 'new':
            items = self.new_items_strids
        elif mode == 'old':
            items = self.caches.itemKeysByStrid.get()
        elif mode == 'autogen_keys':
            items = self.autogenerated_keys
        elif mode == 'items':
            items = self.caches.data_items.get()
        else:
            items = [mode]
            mode = f'single object - {mode}'

        print(f'********** Running in {mode} mode')
        for strid in items:
            try:
                self.do_item(strid)
            except Exception as err:
                print(f'Crashed while processing "{strid}": {err}')
                if self.opts['throw']:
                    raise

    def do_item(self, obj):
        if not obj:
            return
        item = None
        wiki_pages = None

        if type(obj) == str:
            strid = obj
        else:
            item = obj
            strid = strid_from_item(item)
            if not strid:
                print(f'Skipping item without strid {item.id}')
                return
        if strid in self.str_id_variants_count and self.str_id_variants_count[strid] > 1:
            print(f'Skipping ambiguous "{strid}"')
            return
        if strid in self.wiki_items_by_id:
            wiki_pages = self.wiki_items_by_id[strid]
        if strid in self.all_items_by_strid:
            item2 = self.all_items_by_strid[strid]
            if not item:
                item = item2
            elif item2 and item != item2:
                print(f'Skipping {strid} because it matched {item.id} and {item2.id}')
                return
        if self.do_item_run(strid, item, wiki_pages, True):
            if wiki_pages:
                unparsed = self.caches.description.get_new_pages([p.full_title for p in wiki_pages])
                wiki_pages = self.caches.descriptionParsed.parse_manual(unparsed)
            if item:
                item = AttrDict(get_entities(self.site, item.id))
            self.do_item_run(strid, item, wiki_pages, False)

    def do_item_run(self, strid, item, wiki_pages, dry_run):
        parsed_item = ItemFromWiki(self.caches, strid, wiki_pages)
        parsed_item.run()
        parsed_item.print_messages()
        if not parsed_item.ok:
            return False

        status_id = strid if strid else ''
        if item:
            status_id += ' ' + self.caches.qitem(item.id)

        uploader = UploadItem(self.caches, self.autogenerated_keys, self.pb_site, strid, item, parsed_item.editData,
                              parsed_item.claims, self.opts, dry_run)
        uploader.prepare_upload()
        uploader.print_messages()

        if not dry_run and uploader.needs_changes:
            print(f'==== Updating {status_id} ====')
            uploader.upload_item_updates()
            uploader.print_messages()
            print(f'==== Done updating {status_id} ====')

        return uploader.needs_changes

    def get_nonbot_editors(self, qid):
        resp = self.site('query', prop='contributors', pclimit='max', titles='Item:' + qid)
        contributors = [v.name for v in resp.query.pages[0].contributors]
        return ', '.join([c for c in contributors if c != 'Yurikbot']) if contributors != ['Yurikbot'] else False
